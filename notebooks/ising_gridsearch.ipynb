{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8d7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set up path to project root\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Custom modules\n",
    "from src.problems.ising import relaxed_ising_energy, grad_relaxed_ising, ising_energy\n",
    "from src.optimizers.sa import sa_continuous, sa_discrete\n",
    "from src.optimizers.gd import gradient_descent\n",
    "from src.utils.utils_experiments import bootstrap_experiment\n",
    "\n",
    "# Output directory\n",
    "results_dir = os.path.join(project_root, \"results\", \"gridsearch\")\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grids\n",
    "sa_grid = {\n",
    "    'T0': [10, 50, 100],\n",
    "    'alpha': [0.95, 0.99, 0.995],\n",
    "    'step_size': [0.001, 0.01, 0.05, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "gd_grid = {\n",
    "    'lr': [0.0001, 0.001, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "lattice_shape = (10, 10)\n",
    "num_runs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d874f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_sa_discrete(T0, alpha, num_runs=20, hamming_threshold=0):\n",
    "    print(f\"SA-discrete: T0={T0}, alpha={alpha}\")\n",
    "    result = bootstrap_experiment(\n",
    "        sa_discrete,\n",
    "        num_runs,               # <- positional\n",
    "        ising_energy,           # <- positional\n",
    "        lattice_size=lattice_shape,\n",
    "        T_init=T0,\n",
    "        alpha=alpha,\n",
    "        max_iter=50000,\n",
    "        tol=1e-6,\n",
    "        is_discrete=True\n",
    "    )       \n",
    "\n",
    "\n",
    "    # compute energy stats from final values\n",
    "    final_values = np.array(result[\"final_values\"])\n",
    "    final_states = result[\"final_states\"]\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": np.mean(final_values),\n",
    "        \"best\": np.min(final_values),\n",
    "        \"worst\": np.max(final_values),\n",
    "        \"std\": np.std(final_values)\n",
    "    }\n",
    "\n",
    "    # identify best state (lowest energy)\n",
    "    best_idx = np.argmin(final_values)\n",
    "    best_state = final_states[best_idx]\n",
    "\n",
    "    # compute Hamming-based near-optimal count\n",
    "    near_optimal_count = sum(\n",
    "        1 for state in final_states if np.sum(state != best_state) <= hamming_threshold\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"T0\": T0,\n",
    "        \"alpha\": alpha,\n",
    "        \"mean\": stats[\"mean\"],\n",
    "        \"best\": stats[\"best\"],\n",
    "        \"worst\": stats[\"worst\"],\n",
    "        \"std\": stats[\"std\"],\n",
    "        \"near_optimal_count\": near_optimal_count,\n",
    "        \"hamming_threshold\": hamming_threshold\n",
    "    }\n",
    "\n",
    "\n",
    "def grid_search_sa_discrete(grid, num_runs=20, hamming_threshold=0):\n",
    "    results = []\n",
    "    for i, (T0, alpha) in enumerate(tqdm(itertools.product(grid[\"T0\"], grid[\"alpha\"]))):\n",
    "        print(f\"SA-discrete: {i+1}/{len(grid['T0']) * len(grid['alpha'])} combinations\", flush=True)\n",
    "        res = run_one_sa_discrete(T0, alpha, num_runs=num_runs, hamming_threshold=hamming_threshold)\n",
    "        results.append(res)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1bef45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_relaxed_ising(f):\n",
    "    return lambda x: f(x.reshape(lattice_shape))\n",
    "\n",
    "def run_one_sa_continuous(f, T0, alpha, step_size, num_runs=20):\n",
    "    dim = lattice_shape[0] * lattice_shape[1]\n",
    "    result = bootstrap_experiment(\n",
    "        sa_continuous, num_runs, f,\n",
    "        x_init=None, bounds=[(-1, 1)] * dim,\n",
    "        T0=T0, alpha=alpha, step_size=step_size,\n",
    "        tol=1e-6, max_iter=20000\n",
    "    )\n",
    "    stats = result[\"stats\"]\n",
    "    return {\n",
    "        \"T0\": T0, \"alpha\": alpha, \"step_size\": step_size,\n",
    "        \"mean\": stats[\"mean\"], \"best\": stats[\"best\"], \"worst\": stats[\"worst\"],\n",
    "        \"std\": stats[\"std\"], \"epsilon\": stats[\"epsilon\"],\n",
    "        \"near_optimal_count\": stats[\"near_optimal_count\"]\n",
    "    }\n",
    "\n",
    "def grid_search_sa_continuous(f, grid, num_runs=20):\n",
    "    results = []\n",
    "    combinations = list(itertools.product(grid[\"T0\"], grid[\"alpha\"], grid[\"step_size\"]))\n",
    "    for i, (T0, alpha, step_size) in enumerate(tqdm(combinations)):\n",
    "        print(f\"SA-continuous: {i+1}/{len(combinations)} combinations\")\n",
    "        res = run_one_sa_continuous(f, T0, alpha, step_size, num_runs)\n",
    "        results.append(res)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def run_one_gd_continuous(f, grad, lr, num_runs=20):\n",
    "    dim = lattice_shape[0] * lattice_shape[1]\n",
    "    result = bootstrap_experiment(\n",
    "        gradient_descent, num_runs, f, grad,\n",
    "        x_init=None, lr=lr, max_iter=50000, tol=1e-6\n",
    "    )\n",
    "    stats = result[\"stats\"]\n",
    "    return {\n",
    "        \"lr\": lr,\n",
    "        \"mean\": stats[\"mean\"], \"best\": stats[\"best\"], \"worst\": stats[\"worst\"],\n",
    "        \"std\": stats[\"std\"], \"epsilon\": stats[\"epsilon\"],\n",
    "        \"near_optimal_count\": stats[\"near_optimal_count\"]\n",
    "    }\n",
    "\n",
    "def grid_search_gd_continuous(f, grad, grid, num_runs=20):\n",
    "    results = []\n",
    "    for i, lr in enumerate(tqdm(grid[\"lr\"])):\n",
    "        print(f\"GD: {i+1}/{len(grid['lr'])} combinations\")\n",
    "        res = run_one_gd_continuous(f, grad, lr, num_runs)\n",
    "        results.append(res)\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55628d6",
   "metadata": {},
   "source": [
    "# Running actual Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running SA-discrete on ising_energy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA-discrete: 1/9 combinations\n",
      "SA-discrete: T0=10, alpha=0.95\n",
      "Run 1/20...\n",
      "Run 2/20...\n",
      "Run 3/20...\n",
      "Run 4/20...\n",
      "Run 5/20...\n",
      "Run 6/20...\n",
      "Run 7/20...\n",
      "Run 8/20...\n",
      "Run 9/20...\n",
      "Run 10/20...\n",
      "Run 11/20...\n",
      "Run 12/20...\n",
      "Run 13/20...\n",
      "Run 14/20...\n",
      "Run 15/20...\n",
      "Run 16/20...\n",
      "Run 17/20...\n",
      "Run 18/20...\n",
      "Run 19/20...\n",
      "Run 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA-discrete: 2/9 combinations\n",
      "SA-discrete: T0=10, alpha=0.99\n",
      "Run 1/20...\n",
      "Run 2/20...\n",
      "Run 3/20...\n",
      "Run 4/20...\n",
      "Run 5/20...\n",
      "Run 6/20...\n",
      "Run 7/20...\n",
      "Run 8/20...\n",
      "Run 9/20...\n",
      "Run 10/20...\n",
      "Run 11/20...\n",
      "Run 12/20...\n",
      "Run 13/20...\n",
      "Run 14/20...\n",
      "Run 15/20...\n",
      "Run 16/20...\n",
      "Run 17/20...\n",
      "Run 18/20...\n",
      "Run 19/20...\n",
      "Run 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:14,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA-discrete: 3/9 combinations\n",
      "SA-discrete: T0=10, alpha=0.995\n",
      "Run 1/20...\n",
      "Run 2/20...\n",
      "Run 3/20...\n",
      "Run 4/20...\n",
      "Run 5/20...\n",
      "Run 6/20...\n",
      "Run 7/20...\n",
      "Run 8/20...\n",
      "Run 9/20...\n",
      "Run 10/20...\n",
      "Run 11/20...\n",
      "Run 12/20...\n",
      "Run 13/20...\n"
     ]
    }
   ],
   "source": [
    "# Discrete Ising (SA only)\n",
    "print(\"\\nRunning SA-discrete on ising_energy\")\n",
    "df_sa_discrete = grid_search_sa_discrete(sa_grid, num_runs)\n",
    "df_sa_discrete.to_csv(os.path.join(results_dir, \"gridsearch_sa_discrete_ising.csv\"), index=False)\n",
    "\n",
    "# Relaxed Ising (SA)\n",
    "print(\"\\nRunning SA-continuous on relaxed_ising\")\n",
    "relaxed_f = wrap_relaxed_ising(relaxed_ising_energy)\n",
    "df_sa_continuous = grid_search_sa_continuous(relaxed_f, sa_grid, num_runs)\n",
    "df_sa_continuous.to_csv(os.path.join(results_dir, \"gridsearch_sa_continuous_ising.csv\"), index=False)\n",
    "\n",
    "# Relaxed Ising (GD)\n",
    "print(\"\\nRunning GD on relaxed_ising\")\n",
    "grad_wrapped = lambda x: grad_relaxed_ising(x.reshape(lattice_shape)).flatten()\n",
    "df_gd = grid_search_gd_continuous(relaxed_f, grad_wrapped, gd_grid, num_runs)\n",
    "df_gd.to_csv(os.path.join(results_dir, \"gridsearch_gd_ising.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38d94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be41d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
